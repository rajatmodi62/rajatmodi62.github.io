---
layout: page
title: Publications
permalink: /publications/
includelink: true
---

{: style="color: red;"}
**I am currently on the job market and actively searching for new opportunities!**

A lot more still needs to be done. 

2017- 2025 <br>
[1] <u>Asynchronous Perception Machine(s)</u>: First working implementation of the GLOM architecture. It was previously only a theoretical idea. Our implementation is 10x faster than ViT-B/16 and performs 2% better than state-of-the-art OpenCLIP ViT-H on ImageNet. Designed as a spiritual successor to capsule networks.<br>
**Venue:** NeurIPS 2024<br>
**Links:** [[Paper](https://arxiv.org/abs/2410.20535)] [[Poster](https://rajatmodi62.github.io/apm_project_page/)] [[Code](https://rajatmodi62.github.io/apm_project_page/)] [[Patent](https://drive.google.com/file/d/1lz2fZO29fTUk_fqDD2qVSIlQrzSsYQlp/view?usp=drive_link)] <br>

[2] <u>Layer Query Networks</u>: Introduces constant-time feature extraction across any layer in a DNN. While existing networks are sequential ($O(\text{depth})$), LQNs operate in $O(1)$ time. Achieved 15% speedup on ImageNet with 12% relative accuracy improvement.<br>
**Status:** ICLR 2026 (Under Review)<br>
**Links:** [[Paper](https://openreview.net/forum?id=6en51gFQT1)]

[3] <u>On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes</u>:
First benchmark studying occlusions in spatio-temporal video action detection. Introduced 5 new datasets and surpassed VideoCapsuleNet by 32.3%.<br>
**Venue:** NeurIPS 2023<br>
**Links:** [[Paper](https://openreview.net/pdf?id=0cltUI2Sto)] [[Poster](https://drive.google.com/file/d/1OW0B9J6gdf7owtAzV9Ay21ZKfF7Jw1PQ/view?usp=drive_link)] [[Code](https://github.com/rajatmodi62/OccludedActionBenchmark)]

[4] <u>Video Action Detection: Analyzing Limitations And Challenges</u>.
Dataset containing multiple people performing temporally challenging actions (e.g., opening/closing doors). Featured in the official CVPR workshop.<br>
**Venue:** CVPRW 2022<br>
**Links:** [[Paper](https://openaccess.thecvf.com/content/CVPR2022W/VDU/papers/Modi_Video_Action_Detection_Analysing_Limitations_and_Challenges_CVPRW_2022_paper.pdf)] [[Dataset](https://github.com/rajatmodi62/OccludedActionBenchmark)] [[Challenge](https://tinyactions-cvpr22.github.io/)]

[5] <u>Sky2Ground</u>: First dataset consisting of real and synthetic ground/satellite/aerial images for 54 outdoor scenes with camera poses. Proposed **SkyNet**, a 3D point cloud generation architecture using novel curriculum-inspired strategies. Supported by a **$500k grant from IARPA**.<br>
**Status:** CVPR 2026 (Under Review)<br>
**Links:** [[Paper](https://arxiv.org/abs/2410.20535)]

[6] <u>Foundational Models for Video Understanding: A survey</u>: First  survey of over 200 video foundational models and evaluation metrics across 14 video tasks.<br>
**Status:** ACM Computing Survey (Under Review) <br>
**Links:** [[Paper](https://arxiv.org/pdf/2405.03770)] [[GitHub](https://github.com/NeeluMadan/ViFM_Survey)]

[7] <u> Steganography Using Wavelets with statistical performance analysis</u>: An algorithm which forces a stego image to lie within "higher frequencies" range of a  given input image. <br>
**Venue:** IEEE Iementech 2017<br>
**Links:** [[Paper](https://drive.google.com/file/d/1-yK8pPl3p3dzJCtboI367slCHOBZjiPV/view?usp=sharing)]

<!-- [7] <b>Forward-Forward Learning</b>: Improved the Forward-Forward Algorithm for image classification in transformers. Matched backpropagation performance within 2.6% on ImageNet while being 1.8x faster to train.
* **Status:** Under Review -->

## Patents

[1] <u>Asychronous Perception machine</u>
APM is the first implementation to getting GLOM work. Recently filed as an A1 patent application in USPTO by UCF. <br>
Links: [[Patent Application](https://drive.google.com/file/d/1R4NKRI5nVjcgQI9czmf46MTH1qDG7ECj/view?usp=sharing)] 

[1] <u>Externally Guided Multi Domain Personalization:</u>
Invented attribute selection and sampling vectors in GANs to help achieve personalized user recommendations.<br>
Links: [[US A1 Patent](https://drive.google.com/file/d/1R4NKRI5nVjcgQI9czmf46MTH1qDG7ECj/view?usp=sharing)] 

[2] <u>Context Resolution in Autonomous Systems</u>
Propose a system using cross-stitch units to merge user inputs into a unified representation.<br>
Links: [[US A2 Patent](https://patents.google.com/patent/WO2022245134A1/en?inventor=rajat+modi)] 